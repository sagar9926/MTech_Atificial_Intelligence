{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1_Assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvTwwG4GOwVSCG5KHyoDyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/ML1_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKSBNERCD9SM",
        "outputId": "de069de4-3fdf-4e9f-f09c-53c1208a2fc5"
      },
      "source": [
        "!git clone https://github.com/sagar9926/MTech_Atificial_Intelligence.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MTech_Atificial_Intelligence'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 35 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCf9-CcHFAX9",
        "outputId": "f0fe5a42-4690-4fa8-9c9c-e2b4ddd5151f"
      },
      "source": [
        "cd /content/MTech_Atificial_Intelligence/ML1/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MTech_Atificial_Intelligence/ML1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7cK22LdFuHz"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_excel(\"dataset.xlsx\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "66Z75EzKFyhh",
        "outputId": "7c748733-8647-4927-da98-86c2b0b8a3f2"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Class</th>\n",
              "      <th>Actual Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predicted Class  Actual Class\n",
              "0                0             0\n",
              "1                0             0\n",
              "2                1             0\n",
              "3                0             0\n",
              "4                0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0qST7HHdRA",
        "outputId": "abea848e-509a-44a1-93a9-a03d2f391452"
      },
      "source": [
        "data['Actual Class'].unique()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhg7wlH6GLjO"
      },
      "source": [
        "### Calculate overall accuracy and class-wise accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41HW31_fGF3f"
      },
      "source": [
        "def accuracy(data):\r\n",
        "  \r\n",
        "  overall_accuracy = sum(data['Actual Class'] == data['Predicted Class']) / len(data['Actual Class'])\r\n",
        "  print(f\"Overall accuracy of data : {overall_accuracy*100}%\")\r\n",
        "\r\n",
        "  data_class_0 = data[data['Actual Class'] == 0]\r\n",
        "  class_0_accuracy = sum(data_class_0['Actual Class'] == data_class_0['Predicted Class']) / len(data_class_0['Actual Class'])\r\n",
        "  print(f\"Class 0 accuracy of data : {round(class_0_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_1 = data[data['Actual Class'] == 1]\r\n",
        "  class_1_accuracy = sum(data_class_1['Actual Class'] == data_class_1['Predicted Class']) / len(data_class_1['Actual Class'])\r\n",
        "  print(f\"Class 1 accuracy of data : {round(class_1_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_2 = data[data['Actual Class'] == 2]\r\n",
        "  class_2_accuracy = sum(data_class_2['Actual Class'] == data_class_2['Predicted Class']) / len(data_class_2['Actual Class'])\r\n",
        "  print(f\"Class 2 accuracy of data : {round(class_2_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_3 = data[data['Actual Class'] == 3]\r\n",
        "  class_3_accuracy = sum(data_class_3['Actual Class'] == data_class_3['Predicted Class']) / len(data_class_3['Actual Class'])\r\n",
        "  print(f\"Class 3 accuracy of data : {round(class_3_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPUPv4aGlf7",
        "outputId": "fb1278ef-2c74-4001-8216-3c4c979d4526"
      },
      "source": [
        "accuracy(data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 75.625%\n",
            "Class 0 accuracy of data : 67.35%\n",
            "Class 1 accuracy of data : 88.89%\n",
            "Class 2 accuracy of data : 72.5%\n",
            "Class 3 accuracy of data : 77.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWJXa0o9Jkit"
      },
      "source": [
        "### Calculate confusion metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "_T_6TfMDG7QV",
        "outputId": "5f0fa547-d82d-4c9d-a03f-dd56a3329acf"
      },
      "source": [
        "Confusion_matrix = data.groupby(['Predicted Class','Actual Class']).agg({'Predicted Class':'count'})\r\n",
        "Confusion_matrix.columns = ['Instance_count']\r\n",
        "Confusion_matrix['Instance_count'] = Confusion_matrix['Instance_count'].astype(int)\r\n",
        "Confusion_matrix.reset_index(inplace = True)\r\n",
        "Confusion_matrix = Confusion_matrix.pivot(index='Actual Class', columns='Predicted Class', values='Instance_count').fillna(0)\r\n",
        "Confusion_matrix"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted Class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted Class     0     1     2     3\n",
              "Actual Class                           \n",
              "0                33.0   8.0   4.0   4.0\n",
              "1                 1.0  32.0   3.0   0.0\n",
              "2                 3.0   2.0  29.0   6.0\n",
              "3                 2.0   3.0   3.0  27.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ut7DMTPN_I1"
      },
      "source": [
        "### Calculate precision and recall for all classes and report macro average and weighted average values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMTLhncN8YK",
        "outputId": "cca8c069-1974-45bf-a395-8042e2908d2c"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def precision(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  precision = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    precision[each_class] = round((True_positive / (True_positive + False_positive)*100),2)\r\n",
        "    print(f\"Precision of class {each_class} is {precision[each_class]}%\") \r\n",
        "\r\n",
        "  p0 = round(precision[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  p1 = round(precision[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  p2 = round(precision[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  p3 = round(precision[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_precision = round(p0 + p1 + p2 + p3,2)\r\n",
        "  print(f\"Macro Precision of class is {round((precision[0] + precision[1] +precision[2] +precision[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Precision of class is {weighted_precision}%\") \r\n",
        "  \r\n",
        "  return precision\r\n",
        "precision = precision(data)\r\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of class 0 is 84.62%\n",
            "Precision of class 1 is 71.11%\n",
            "Precision of class 2 is 74.36%\n",
            "Precision of class 3 is 72.97%\n",
            "Macro Precision of class is 75.77%\n",
            "Weighted Precision of class is 76.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOMH2qPZTLtY",
        "outputId": "955e47ef-ea2b-4389-b38f-722512fc24b1"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def recall(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  recall = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    recall[each_class] = round((True_positive / (True_positive + False_negative)*100),2)\r\n",
        "    print(f\"Recall of class {each_class} is {recall[each_class]}%\") \r\n",
        "\r\n",
        "  r0 = round(recall[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  r1 = round(recall[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  r2 = round(recall[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  r3 = round(recall[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_recall = round(r0 + r1 + r2 + r3,2)\r\n",
        "  print(f\"Macro Recall of class is {round((recall[0] + recall[1] + recall[2] + recall[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Recall of class is {weighted_recall}%\") \r\n",
        "  \r\n",
        "  return recall\r\n",
        "recall = recall(data)\r\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall of class 0 is 67.35%\n",
            "Recall of class 1 is 88.89%\n",
            "Recall of class 2 is 72.5%\n",
            "Recall of class 3 is 77.14%\n",
            "Macro Recall of class is 76.47%\n",
            "Weighted Recall of class is 75.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "galsM9H0a_uX"
      },
      "source": [
        "### Calculate F1 score for all classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsEbY-dFT101",
        "outputId": "44c25d20-d6e4-41aa-8d59-f0f28dd35d2e"
      },
      "source": [
        "classes = data['Actual Class'].sort_values().unique()\r\n",
        "for each_class in classes:\r\n",
        "  F1 = 2*precision[each_class] * recall[each_class]/(precision[each_class] + recall[each_class])\r\n",
        "  print(f\"F1 score of class {each_class} is {round(F1,2)}\" )\r\n",
        "  "
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of class 0 is 75.0\n",
            "F1 score of class 1 is 79.01\n",
            "F1 score of class 2 is 73.42\n",
            "F1 score of class 3 is 75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTD-GX5Cbzwk"
      },
      "source": [
        "### Report Type-1 and Type-II error for given data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy0hULoAbMu6",
        "outputId": "96cc7cac-516a-4901-d4d6-6724c989883c"
      },
      "source": [
        "def Type1_Type2_error(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  Type1 = {}\r\n",
        "  Type2 = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    True_negative = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "\r\n",
        "    Type1[each_class] = round((False_positive / (False_positive + True_negative)*100),2)\r\n",
        "    Type2[each_class] = round((False_negative / (False_negative + True_positive)*100),2)\r\n",
        "    print(f\"Type 1 error of class {each_class} is {Type1[each_class]}%\") \r\n",
        "    print(f\"Type 2 error of class {each_class} is {Type2[each_class]}%\") \r\n",
        "Type1_Type2_error(data)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type 1 error of class 0 is 5.41%\n",
            "Type 2 error of class 0 is 32.65%\n",
            "Type 1 error of class 1 is 10.48%\n",
            "Type 2 error of class 1 is 11.11%\n",
            "Type 1 error of class 2 is 8.33%\n",
            "Type 2 error of class 2 is 27.5%\n",
            "Type 1 error of class 3 is 8.0%\n",
            "Type 2 error of class 3 is 22.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3dznI70ga-T"
      },
      "source": [
        "### Draw a comparison table between above determined values and values observed from sklearn library (predefined library for performance evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMBSD4FYfQ6D",
        "outputId": "08a09d53-14f8-4ee1-dd8b-092adc5e3522"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\r\n",
        "y_true = data['Actual Class']\r\n",
        "y_pred = data['Predicted Class']\r\n",
        "confusion_matrix(y_true,y_pred)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[33,  8,  4,  4],\n",
              "       [ 1, 32,  3,  0],\n",
              "       [ 3,  2, 29,  6],\n",
              "       [ 2,  3,  3, 27]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXdBZ3K7gym_",
        "outputId": "51245bcd-9279-4eda-e71c-4b532e500b1f"
      },
      "source": [
        "accuracy_score(y_true,y_false)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk4pnvOthc_Y",
        "outputId": "5e3bd9ec-1f58-43aa-c30d-14bbb8fa39ae"
      },
      "source": [
        "matrix = confusion_matrix(y_true, y_pred)\r\n",
        "matrix.diagonal()/matrix.sum(axis=1)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.67346939, 0.88888889, 0.725     , 0.77142857])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "TpcNTvwshkZd",
        "outputId": "d4e4d32c-85b5-48a7-cb75-e6d7cdbdbe9e"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "classes = data['Actual Class'].sort_values().unique()\r\n",
        "classification_report(y_true, y_pred,target_names=classes)\r\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-1d558bd23966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' {:>9}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBDskQBrifYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}