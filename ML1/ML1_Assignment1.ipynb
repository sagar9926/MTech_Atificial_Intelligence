{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1_Assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPUMe8cliVx0/QYUDoZLhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/ML1_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKSBNERCD9SM",
        "outputId": "7ae1710b-51ca-4031-d61c-1d81ed1b6b1b"
      },
      "source": [
        "!git clone https://github.com/sagar9926/MTech_Atificial_Intelligence.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MTech_Atificial_Intelligence'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 47 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCf9-CcHFAX9",
        "outputId": "0983633e-39cb-4687-aa23-da866ffebaf7"
      },
      "source": [
        "cd /content/MTech_Atificial_Intelligence/ML1/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MTech_Atificial_Intelligence/ML1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7cK22LdFuHz"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_excel(\"dataset.xlsx\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "66Z75EzKFyhh",
        "outputId": "0dbd52cf-ff84-4135-900a-b0306aedd983"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Class</th>\n",
              "      <th>Actual Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predicted Class  Actual Class\n",
              "0                0             0\n",
              "1                0             0\n",
              "2                1             0\n",
              "3                0             0\n",
              "4                0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0qST7HHdRA",
        "outputId": "d4a42d0b-5709-4bd3-97df-cf00ec3d42cb"
      },
      "source": [
        "data['Actual Class'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhg7wlH6GLjO"
      },
      "source": [
        "### Calculate overall accuracy and class-wise accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41HW31_fGF3f"
      },
      "source": [
        "def accuracy(data):\r\n",
        "  \r\n",
        "  overall_accuracy = sum(data['Actual Class'] == data['Predicted Class']) / len(data['Actual Class'])\r\n",
        "  print(f\"Overall accuracy of data : {overall_accuracy*100}%\")\r\n",
        "\r\n",
        "  data_class_0 = data[data['Actual Class'] == 0]\r\n",
        "  class_0_accuracy = sum(data_class_0['Actual Class'] == data_class_0['Predicted Class']) / len(data_class_0['Actual Class'])\r\n",
        "  print(f\"Class 0 accuracy of data : {round(class_0_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_1 = data[data['Actual Class'] == 1]\r\n",
        "  class_1_accuracy = sum(data_class_1['Actual Class'] == data_class_1['Predicted Class']) / len(data_class_1['Actual Class'])\r\n",
        "  print(f\"Class 1 accuracy of data : {round(class_1_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_2 = data[data['Actual Class'] == 2]\r\n",
        "  class_2_accuracy = sum(data_class_2['Actual Class'] == data_class_2['Predicted Class']) / len(data_class_2['Actual Class'])\r\n",
        "  print(f\"Class 2 accuracy of data : {round(class_2_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_3 = data[data['Actual Class'] == 3]\r\n",
        "  class_3_accuracy = sum(data_class_3['Actual Class'] == data_class_3['Predicted Class']) / len(data_class_3['Actual Class'])\r\n",
        "  print(f\"Class 3 accuracy of data : {round(class_3_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPUPv4aGlf7",
        "outputId": "0756aad7-caff-460b-d508-06da38b1dc64"
      },
      "source": [
        "accuracy(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 75.625%\n",
            "Class 0 accuracy of data : 67.35%\n",
            "Class 1 accuracy of data : 88.89%\n",
            "Class 2 accuracy of data : 72.5%\n",
            "Class 3 accuracy of data : 77.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWJXa0o9Jkit"
      },
      "source": [
        "### Calculate confusion metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "_T_6TfMDG7QV",
        "outputId": "4c9ff4e0-fbb5-43f9-da15-45142493f538"
      },
      "source": [
        "Confusion_matrix = data.groupby(['Predicted Class','Actual Class']).agg({'Predicted Class':'count'})\r\n",
        "Confusion_matrix.columns = ['Instance_count']\r\n",
        "Confusion_matrix['Instance_count'] = Confusion_matrix['Instance_count'].astype(int)\r\n",
        "Confusion_matrix.reset_index(inplace = True)\r\n",
        "Confusion_matrix = Confusion_matrix.pivot(index='Actual Class', columns='Predicted Class', values='Instance_count').fillna(0)\r\n",
        "Confusion_matrix"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted Class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted Class     0     1     2     3\n",
              "Actual Class                           \n",
              "0                33.0   8.0   4.0   4.0\n",
              "1                 1.0  32.0   3.0   0.0\n",
              "2                 3.0   2.0  29.0   6.0\n",
              "3                 2.0   3.0   3.0  27.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ut7DMTPN_I1"
      },
      "source": [
        "### Calculate precision and recall for all classes and report macro average and weighted average values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMTLhncN8YK",
        "outputId": "35531276-3e71-4c6b-fbc8-5ab11ce54aa4"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def precision(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  precision = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    precision[each_class] = round((True_positive / (True_positive + False_positive)*100),2)\r\n",
        "    print(f\"Precision of class {each_class} is {precision[each_class]}%\") \r\n",
        "\r\n",
        "  p0 = round(precision[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  p1 = round(precision[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  p2 = round(precision[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  p3 = round(precision[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_precision = round(p0 + p1 + p2 + p3,2)\r\n",
        "  print(f\"Macro Precision of class is {round((precision[0] + precision[1] +precision[2] +precision[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Precision of class is {weighted_precision}%\") \r\n",
        "  \r\n",
        "  return precision\r\n",
        "precision = precision(data)\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of class 0 is 84.62%\n",
            "Precision of class 1 is 71.11%\n",
            "Precision of class 2 is 74.36%\n",
            "Precision of class 3 is 72.97%\n",
            "Macro Precision of class is 75.77%\n",
            "Weighted Precision of class is 76.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOMH2qPZTLtY",
        "outputId": "7b9131e7-af00-49f9-cf80-72e879b46e75"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def recall(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  recall = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    recall[each_class] = round((True_positive / (True_positive + False_negative)*100),2)\r\n",
        "    print(f\"Recall of class {each_class} is {recall[each_class]}%\") \r\n",
        "\r\n",
        "  r0 = round(recall[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  r1 = round(recall[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  r2 = round(recall[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  r3 = round(recall[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_recall = round(r0 + r1 + r2 + r3,2)\r\n",
        "  print(f\"Macro Recall of class is {round((recall[0] + recall[1] + recall[2] + recall[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Recall of class is {weighted_recall}%\") \r\n",
        "  \r\n",
        "  return recall\r\n",
        "recall = recall(data)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall of class 0 is 67.35%\n",
            "Recall of class 1 is 88.89%\n",
            "Recall of class 2 is 72.5%\n",
            "Recall of class 3 is 77.14%\n",
            "Macro Recall of class is 76.47%\n",
            "Weighted Recall of class is 75.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "galsM9H0a_uX"
      },
      "source": [
        "### Calculate F1 score for all classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsEbY-dFT101",
        "outputId": "583b128c-c557-4a77-ffac-5dc4878d7268"
      },
      "source": [
        "classes = data['Actual Class'].sort_values().unique()\r\n",
        "F1_score = {}\r\n",
        "for each_class in classes:\r\n",
        "  F1 = 2*precision[each_class] * recall[each_class]/(precision[each_class] + recall[each_class])\r\n",
        "  F1_score[each_class] = F1\r\n",
        "  print(f\"F1 score of class {each_class} is {round(F1,2)}\" )\r\n",
        "\r\n",
        "f0 = round(F1_score[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "f1 = round(F1_score[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "f2 = round(F1_score[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "f3 = round(F1_score[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "weighted_F1 = round(f0 + f1 + f2 + f3,2)\r\n",
        "print(f\"Macro Recall of class is {round((F1_score[0] + F1_score[1] + F1_score[2] + F1_score[3])/4,2)}%\") \r\n",
        "print(f\"Weighted Recall of class is {weighted_F1}%\") \r\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of class 0 is 75.0\n",
            "F1 score of class 1 is 79.01\n",
            "F1 score of class 2 is 73.42\n",
            "F1 score of class 3 is 75.0\n",
            "Macro Recall of class is 75.61%\n",
            "Weighted Recall of class is 75.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTD-GX5Cbzwk"
      },
      "source": [
        "### Report Type-1 and Type-II error for given data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy0hULoAbMu6",
        "outputId": "8a0155ca-4d01-487c-ea17-02402717a10a"
      },
      "source": [
        "def Type1_Type2_error(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  Type1 = {}\r\n",
        "  Type2 = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    True_negative = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "\r\n",
        "    Type1[each_class] = round((False_positive / (False_positive + True_negative)*100),2)\r\n",
        "    Type2[each_class] = round((False_negative / (False_negative + True_positive)*100),2)\r\n",
        "    print(f\"Type 1 error of class {each_class} is {Type1[each_class]}%\") \r\n",
        "    print(f\"Type 2 error of class {each_class} is {Type2[each_class]}%\") \r\n",
        "Type1_Type2_error(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type 1 error of class 0 is 5.41%\n",
            "Type 2 error of class 0 is 32.65%\n",
            "Type 1 error of class 1 is 10.48%\n",
            "Type 2 error of class 1 is 11.11%\n",
            "Type 1 error of class 2 is 8.33%\n",
            "Type 2 error of class 2 is 27.5%\n",
            "Type 1 error of class 3 is 8.0%\n",
            "Type 2 error of class 3 is 22.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3dznI70ga-T"
      },
      "source": [
        "### Draw a comparison table between above determined values and values observed from sklearn library (predefined library for performance evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDskQBrifYF",
        "outputId": "655b4fd5-35c3-4928-fe90-820b80961a1c"
      },
      "source": [
        "y_true = data['Actual Class']\r\n",
        "y_pred = data['Predicted Class']\r\n",
        "\r\n",
        "#importing confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y_true, y_pred)\r\n",
        "print(f'Confusion Matrix :\\n {cm}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            " [[33  8  4  4]\n",
            " [ 1 32  3  0]\n",
            " [ 3  2 29  6]\n",
            " [ 2  3  3 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihGDkcDckDzm",
        "outputId": "2c3f855f-c942-42bd-db73-5beaeb5cfb4f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
        "print(f'Accuracy:{accuracy_score(y_true, y_pred)}')\r\n",
        "\r\n",
        "print(f'Macro Precision: ',round(precision_score(y_true, y_pred, average='macro')*100,2))\r\n",
        "print(f'Macro Recall: ' ,round(recall_score(y_true, y_pred, average='macro')*100,2))\r\n",
        "print(f'Macro F1-score: ' ,round(f1_score(y_true, y_pred, average='macro')*100,2))\r\n",
        "\r\n",
        "print(f'Weighted Precision: ' ,round(precision_score(y_true, y_pred, average='weighted')*100,2))\r\n",
        "print(f'Weighted Recall:' ,round(recall_score(y_true, y_pred, average='weighted')*100,2))\r\n",
        "print(f'Weighted F1-score:' ,round(f1_score(y_true, y_pred, average='weighted')*100,2))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.75625\n",
            "Macro Precision:  75.76\n",
            "Macro Recall:  76.47\n",
            "Macro F1-score:  75.61\n",
            "Weighted Precision:  76.47\n",
            "Weighted Recall: 75.62\n",
            "Weighted F1-score: 75.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibHDlyAmeNu",
        "outputId": "822402ee-530d-4be7-97ae-98da14319c3e"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "print('\\nClassification Report\\n')\r\n",
        "print(classification_report(y_true, y_pred, target_names=['Class 0','Class 1', 'Class 2', 'Class 3']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.85      0.67      0.75        49\n",
            "     Class 1       0.71      0.89      0.79        36\n",
            "     Class 2       0.74      0.72      0.73        40\n",
            "     Class 3       0.73      0.77      0.75        35\n",
            "\n",
            "    accuracy                           0.76       160\n",
            "   macro avg       0.76      0.76      0.76       160\n",
            "weighted avg       0.76      0.76      0.76       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDUM-fTS-Hn1"
      },
      "source": [
        "### Use any 2 metrics from Question 1 for implementation and report your results for this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymlF5D-V-gTj"
      },
      "source": [
        "#### F-Beta Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIsfqNz4wGsq",
        "outputId": "ab6ac062-aedf-49e6-c8aa-2d26282df091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import fbeta_score\r\n",
        "print(\"Macro F-Beta score :\",round(fbeta_score(y_true, y_pred, average='macro', beta=0.5),4)*100)\r\n",
        "\r\n",
        "print(\"Micro F-Beta score :\",round(fbeta_score(y_true, y_pred, average='micro', beta=0.5),4)*100)\r\n",
        "\r\n",
        "print(\"Weighted F-Beta score :\",round(fbeta_score(y_true, y_pred, average='weighted', beta=0.5),3)*100)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro F-Beta score : 75.58\n",
            "Micro F-Beta score : 75.62\n",
            "Weighted F-Beta score : 75.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfh8QZ_U_NqM"
      },
      "source": [
        "#### Hamming Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncRJGtBz-4dT",
        "outputId": "9e92eb8f-23ab-47c3-8339-3c3265160b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import hamming_loss\r\n",
        "\r\n",
        "print(\"Hamming Loss :\",hamming_loss(y_true, y_pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hamming Loss : 0.24375\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}