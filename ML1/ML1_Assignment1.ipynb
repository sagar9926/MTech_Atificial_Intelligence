{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1_Assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPacozWbm/fM8UnWRJCW+az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/ML1_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKSBNERCD9SM",
        "outputId": "de069de4-3fdf-4e9f-f09c-53c1208a2fc5"
      },
      "source": [
        "!git clone https://github.com/sagar9926/MTech_Atificial_Intelligence.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MTech_Atificial_Intelligence'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 35 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCf9-CcHFAX9",
        "outputId": "f0fe5a42-4690-4fa8-9c9c-e2b4ddd5151f"
      },
      "source": [
        "cd /content/MTech_Atificial_Intelligence/ML1/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MTech_Atificial_Intelligence/ML1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7cK22LdFuHz"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_excel(\"dataset.xlsx\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "66Z75EzKFyhh",
        "outputId": "7c748733-8647-4927-da98-86c2b0b8a3f2"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Class</th>\n",
              "      <th>Actual Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predicted Class  Actual Class\n",
              "0                0             0\n",
              "1                0             0\n",
              "2                1             0\n",
              "3                0             0\n",
              "4                0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0qST7HHdRA",
        "outputId": "abea848e-509a-44a1-93a9-a03d2f391452"
      },
      "source": [
        "data['Actual Class'].unique()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhg7wlH6GLjO"
      },
      "source": [
        "### Calculate overall accuracy and class-wise accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41HW31_fGF3f"
      },
      "source": [
        "def accuracy(data):\r\n",
        "  \r\n",
        "  overall_accuracy = sum(data['Actual Class'] == data['Predicted Class']) / len(data['Actual Class'])\r\n",
        "  print(f\"Overall accuracy of data : {overall_accuracy*100}%\")\r\n",
        "\r\n",
        "  data_class_0 = data[data['Actual Class'] == 0]\r\n",
        "  class_0_accuracy = sum(data_class_0['Actual Class'] == data_class_0['Predicted Class']) / len(data_class_0['Actual Class'])\r\n",
        "  print(f\"Class 0 accuracy of data : {round(class_0_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_1 = data[data['Actual Class'] == 1]\r\n",
        "  class_1_accuracy = sum(data_class_1['Actual Class'] == data_class_1['Predicted Class']) / len(data_class_1['Actual Class'])\r\n",
        "  print(f\"Class 1 accuracy of data : {round(class_1_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_2 = data[data['Actual Class'] == 2]\r\n",
        "  class_2_accuracy = sum(data_class_2['Actual Class'] == data_class_2['Predicted Class']) / len(data_class_2['Actual Class'])\r\n",
        "  print(f\"Class 2 accuracy of data : {round(class_2_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "  data_class_3 = data[data['Actual Class'] == 3]\r\n",
        "  class_3_accuracy = sum(data_class_3['Actual Class'] == data_class_3['Predicted Class']) / len(data_class_3['Actual Class'])\r\n",
        "  print(f\"Class 3 accuracy of data : {round(class_3_accuracy*100,2)}%\")\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPUPv4aGlf7",
        "outputId": "fb1278ef-2c74-4001-8216-3c4c979d4526"
      },
      "source": [
        "accuracy(data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 75.625%\n",
            "Class 0 accuracy of data : 67.35%\n",
            "Class 1 accuracy of data : 88.89%\n",
            "Class 2 accuracy of data : 72.5%\n",
            "Class 3 accuracy of data : 77.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWJXa0o9Jkit"
      },
      "source": [
        "### Calculate confusion metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "_T_6TfMDG7QV",
        "outputId": "5f0fa547-d82d-4c9d-a03f-dd56a3329acf"
      },
      "source": [
        "Confusion_matrix = data.groupby(['Predicted Class','Actual Class']).agg({'Predicted Class':'count'})\r\n",
        "Confusion_matrix.columns = ['Instance_count']\r\n",
        "Confusion_matrix['Instance_count'] = Confusion_matrix['Instance_count'].astype(int)\r\n",
        "Confusion_matrix.reset_index(inplace = True)\r\n",
        "Confusion_matrix = Confusion_matrix.pivot(index='Actual Class', columns='Predicted Class', values='Instance_count').fillna(0)\r\n",
        "Confusion_matrix"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted Class</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted Class     0     1     2     3\n",
              "Actual Class                           \n",
              "0                33.0   8.0   4.0   4.0\n",
              "1                 1.0  32.0   3.0   0.0\n",
              "2                 3.0   2.0  29.0   6.0\n",
              "3                 2.0   3.0   3.0  27.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ut7DMTPN_I1"
      },
      "source": [
        "### Calculate precision and recall for all classes and report macro average and weighted average values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMTLhncN8YK",
        "outputId": "cca8c069-1974-45bf-a395-8042e2908d2c"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def precision(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  precision = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    precision[each_class] = round((True_positive / (True_positive + False_positive)*100),2)\r\n",
        "    print(f\"Precision of class {each_class} is {precision[each_class]}%\") \r\n",
        "\r\n",
        "  p0 = round(precision[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  p1 = round(precision[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  p2 = round(precision[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  p3 = round(precision[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_precision = round(p0 + p1 + p2 + p3,2)\r\n",
        "  print(f\"Macro Precision of class is {round((precision[0] + precision[1] +precision[2] +precision[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Precision of class is {weighted_precision}%\") \r\n",
        "  \r\n",
        "  return precision\r\n",
        "precision = precision(data)\r\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision of class 0 is 84.62%\n",
            "Precision of class 1 is 71.11%\n",
            "Precision of class 2 is 74.36%\n",
            "Precision of class 3 is 72.97%\n",
            "Macro Precision of class is 75.77%\n",
            "Weighted Precision of class is 76.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOMH2qPZTLtY",
        "outputId": "955e47ef-ea2b-4389-b38f-722512fc24b1"
      },
      "source": [
        "from functools import reduce\r\n",
        "\r\n",
        "def recall(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  recall = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    recall[each_class] = round((True_positive / (True_positive + False_negative)*100),2)\r\n",
        "    print(f\"Recall of class {each_class} is {recall[each_class]}%\") \r\n",
        "\r\n",
        "  r0 = round(recall[0]*data[(data['Actual Class'] == 0)].shape[0]/data.shape[0] , 2)\r\n",
        "  r1 = round(recall[1]*data[(data['Actual Class'] == 1)].shape[0]/data.shape[0] , 2)\r\n",
        "  r2 = round(recall[2]*data[(data['Actual Class'] == 2)].shape[0]/data.shape[0] , 2)\r\n",
        "  r3 = round(recall[3]*data[(data['Actual Class'] == 3)].shape[0]/data.shape[0] , 2)\r\n",
        "  weighted_recall = round(r0 + r1 + r2 + r3,2)\r\n",
        "  print(f\"Macro Recall of class is {round((recall[0] + recall[1] + recall[2] + recall[3])/4,2)}%\") \r\n",
        "  print(f\"Weighted Recall of class is {weighted_recall}%\") \r\n",
        "  \r\n",
        "  return recall\r\n",
        "recall = recall(data)\r\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall of class 0 is 67.35%\n",
            "Recall of class 1 is 88.89%\n",
            "Recall of class 2 is 72.5%\n",
            "Recall of class 3 is 77.14%\n",
            "Macro Recall of class is 76.47%\n",
            "Weighted Recall of class is 75.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "galsM9H0a_uX"
      },
      "source": [
        "### Calculate F1 score for all classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsEbY-dFT101",
        "outputId": "44c25d20-d6e4-41aa-8d59-f0f28dd35d2e"
      },
      "source": [
        "classes = data['Actual Class'].sort_values().unique()\r\n",
        "for each_class in classes:\r\n",
        "  F1 = 2*precision[each_class] * recall[each_class]/(precision[each_class] + recall[each_class])\r\n",
        "  print(f\"F1 score of class {each_class} is {round(F1,2)}\" )\r\n",
        "  "
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of class 0 is 75.0\n",
            "F1 score of class 1 is 79.01\n",
            "F1 score of class 2 is 73.42\n",
            "F1 score of class 3 is 75.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTD-GX5Cbzwk"
      },
      "source": [
        "### Report Type-1 and Type-II error for given data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy0hULoAbMu6",
        "outputId": "96cc7cac-516a-4901-d4d6-6724c989883c"
      },
      "source": [
        "def Type1_Type2_error(data):\r\n",
        "  classes = data['Actual Class'].sort_values().unique()\r\n",
        "  Type1 = {}\r\n",
        "  Type2 = {}\r\n",
        "  for each_class in classes:\r\n",
        "    True_positive = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    True_negative = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "    False_positive = data[(data['Actual Class'] != each_class) & (data['Predicted Class'] == each_class)].shape[0]\r\n",
        "    False_negative = data[(data['Actual Class'] == each_class) & (data['Predicted Class'] != each_class)].shape[0]\r\n",
        "\r\n",
        "    Type1[each_class] = round((False_positive / (False_positive + True_negative)*100),2)\r\n",
        "    Type2[each_class] = round((False_negative / (False_negative + True_positive)*100),2)\r\n",
        "    print(f\"Type 1 error of class {each_class} is {Type1[each_class]}%\") \r\n",
        "    print(f\"Type 2 error of class {each_class} is {Type2[each_class]}%\") \r\n",
        "Type1_Type2_error(data)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type 1 error of class 0 is 5.41%\n",
            "Type 2 error of class 0 is 32.65%\n",
            "Type 1 error of class 1 is 10.48%\n",
            "Type 2 error of class 1 is 11.11%\n",
            "Type 1 error of class 2 is 8.33%\n",
            "Type 2 error of class 2 is 27.5%\n",
            "Type 1 error of class 3 is 8.0%\n",
            "Type 2 error of class 3 is 22.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3dznI70ga-T"
      },
      "source": [
        "### Draw a comparison table between above determined values and values observed from sklearn library (predefined library for performance evaluation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDskQBrifYF",
        "outputId": "42163c8f-ec39-4bb5-fa33-577a6e0a5787"
      },
      "source": [
        "y_true = data['Actual Class']\r\n",
        "y_pred = data['Predicted Class']\r\n",
        "\r\n",
        "#importing confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y_true, y_pred)\r\n",
        "print(f'Confusion Matrix :\\n {cm}')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            " [[33  8  4  4]\n",
            " [ 1 32  3  0]\n",
            " [ 3  2 29  6]\n",
            " [ 2  3  3 27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihGDkcDckDzm",
        "outputId": "3079ef99-cbb0-4aa5-be62-f2a6b8be0b87"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
        "print(f'Accuracy:{accuracy_score(y_true, y_pred)}')\r\n",
        "print(f'Macro Precision: ',round(precision_score(y_true, y_pred, average='macro')*100,2))\r\n",
        "# print(f'Macro Recall: {(recall_score(y_true, y_pred, average='macro'))}')\r\n",
        "# print(f'Macro F1-score: {(f1_score(y_true, y_pred, average='macro'))}')\r\n",
        "# print(f'Weighted Precision:{(precision_score(y_true, y_pred, average='weighted'))}')\r\n",
        "# print(f'Weighted Recall: {(recall_score(y_true, y_pred, average='weighted'))}')\r\n",
        "# print(f'Weighted F1-score: {(f1_score(y_true, y_pred, average='weighted'))}')\r\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.75625\n",
            "Macro Precision:  75.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibHDlyAmeNu",
        "outputId": "d7b54746-a1fe-41ef-c7ce-17fee60229b8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
        "\r\n",
        "#precision_score(y_true, y_pred, average='macro')\r\n",
        "print(precision_score(y_true, y_pred,average='macro'))\r\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7576461076461076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj_G7upBmvT1",
        "outputId": "af6ff152-85cd-433f-e4b2-f5c44dba2112"
      },
      "source": [
        "print(f'Accuracy:{accuracy_score(y_true, y_pred)}')\r\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.75625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W1DprBunIah"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}