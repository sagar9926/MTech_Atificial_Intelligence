{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Fractal3 AssignmentProblem 2.3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/Fractal3_Assignment/ML_Fractal3_AssignmentProblem_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBepk4ocLmNc"
      },
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLNY0x5Hh8ic",
        "outputId": "bc03b97a-5642-4584-9089-a102efb8134f"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-zj2OdmMcZU",
        "outputId": "894cfb5e-381a-420c-8c72-6f40a49a8d07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1CAbhwtNGxu"
      },
      "source": [
        "class GurmukhiDataset(Dataset):\n",
        "\n",
        "  def __init__(self,transform=None , train_data = False , val_data = False):\n",
        "    self.transform = transform\n",
        "    if train_data :\n",
        "      self.data_path = \"/content/gdrive/MyDrive/Gurmukhi/GurNum/train/\"\n",
        "    elif val_data :\n",
        "      self.data_path = \"/content/gdrive/MyDrive/Gurmukhi/GurNum/val/\"\n",
        "\n",
        "    image_file_list = glob.glob(self.data_path + \"*\")\n",
        "    self.data = []\n",
        "\n",
        "    for path in image_file_list:\n",
        "      class_name = int(path.split(\"/\")[-1])\n",
        "      for image_path in glob.glob(path + \"/*.*\"):\n",
        "        self.data.append([image_path, class_name])\n",
        "        self.img_dim = (32, 32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return(len(self.data))\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_path, class_name = self.data[idx]\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, self.img_dim)\n",
        "    if self.transform:\n",
        "      img_tensor = self.transform(img)\n",
        "    #img_tensor = torch.from_numpy(img)\n",
        "    #print(img_tensor.shape)\n",
        "    #Torch convolutions require images to be in a channel first format; \n",
        "    #i.e for example a 3 channel image(Red, Green and Blue channels) would be generally represented as: \n",
        "    #(Width, Height, Channels) in numpy, however torch requires us to convert this to: (Channels, Width, Height).\n",
        "    # For this conversion we use the permute function of torch, that allows us to change the ordering of the dimensions of a torch tensor.\n",
        "\n",
        "    #img_tensor = img_tensor.permute(2, 0, 1)\n",
        "    class_name = torch.tensor([class_name],dtype = torch.long)\n",
        "    return img_tensor.float(), class_name\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs_BwqBTTYmt"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation((-4.0, 4.0)),\n",
        "    #transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUZk05QSNTKo"
      },
      "source": [
        "train_dataset = GurmukhiDataset(transform = transform_train,train_data = True)\n",
        "val_dataset = GurmukhiDataset(transform = transform_test,val_data = True)\n",
        "trainloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im9270A_XE-b"
      },
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kTlfDhaXma7",
        "outputId": "cf95692e-a3dd-4f73-d574-4bb7fc13b10d"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next() # this gives us one instance of four images and their corresponding labels\n",
        "\n",
        "torchvision.utils.make_grid(images).shape \n",
        "# This represents the stacked images of the batch with 2 pixel padding (32* 4 + 2*5(black borders) = 138)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 36, 138])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "EWVR6tV3XuNT",
        "outputId": "b2695965-a05f-450d-b0d5-d282cd0ea633"
      },
      "source": [
        "imshow(torchvision.utils.make_grid(images)) #To plot the entire batch, stacks up the images in form of long image in which individual image will apper in cells\n",
        "print(\"True Classes : \",' '.join(str(labels[j]) for j in range(4)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "True Classes :  tensor([0]) tensor([0]) tensor([7]) tensor([5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFUX-rVgbkh5"
      },
      "source": [
        "train_dataset = GurmukhiDataset(transform = transform_train,train_data = True)\n",
        "val_dataset = GurmukhiDataset(transform = transform_test,val_data = True)\n",
        "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XE45O01a76E"
      },
      "source": [
        "#Final Version\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(8),   \n",
        "            nn.ReLU()\n",
        "         \n",
        "        ) # output_size = [N , 8 , 30 , 30]\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),   \n",
        "            nn.ReLU()\n",
        "         \n",
        "        ) # output_size = [N , 16 , 28 , 28]\n",
        "\n",
        "        # pooling layer\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = [N , 16 , 14 , 14]\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(32), \n",
        "            nn.ReLU()\n",
        "        ) # output_size = [N , 32 , 12 , 12]\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(48), \n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25)\n",
        "        ) # output_size = [N , 48 , 10 , 10]\n",
        "\n",
        "        # pooling layer\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = [N , 48 , 5 , 5]\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(in_channels=48, out_channels=96, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = [N , 192 , 6 , 6]\n",
        "\n",
        " \n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(2400,512),         # (N, 400) -> (N, 120)\n",
        "            nn.Dropout(0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,512),          # (N, 120) -> (N, 84)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Linear(512,256),          # (N, 120) -> (N, 84)\n",
        "\n",
        "            nn.Linear(256,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        \n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.convblock5(x)\n",
        "        #x = self.convblock6(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1) # (N, 16, 5, 5) -> (N, 400)\n",
        "        x = self.fc_model(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=-1)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN6bjnjXwZed"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=48, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(48),   \n",
        "            nn.ReLU()\n",
        "         \n",
        "        ) # output_size = [N , 48 , 32 , 32]\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(48),   \n",
        "            nn.ReLU()\n",
        "         \n",
        "        ) # output_size = [N , 48 , 30 , 30]\n",
        "\n",
        "        # pooling layer\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = [N , 48 , 15 , 15]\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(in_channels=48, out_channels=96, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(96), \n",
        "            nn.ReLU()\n",
        "        ) # output_size = [N , 96 , 15 , 15]\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            #nn.Dropout(0.25),\n",
        "            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(96), \n",
        "            nn.ReLU()\n",
        "        ) # output_size = [N , 96 , 13 , 13]\n",
        "\n",
        "        # pooling layer\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = [N , 96 , 6 , 6]\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU()\n",
        "        ) # output_size = [N , 192 , 6 , 6]\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.35)\n",
        "        ) # output_size = [N , 192 , 4 , 4]\n",
        "\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(3072*2,512),         # (N, 400) -> (N, 120)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.Linear(512,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.Linear(512,256),          # (N, 120) -> (N, 84)\n",
        "            nn.Linear(256,10)            # (N, 84)  -> (N, 10)\n",
        "        )\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        img = copy.deepcopy(x)\n",
        "               \n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        \n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = x.view(x.size(0), -1) # (N, 16, 5, 5) -> (N, 400)\n",
        "        \n",
        "        x = torch.cat((x,img.reshape(x.size(0),-1)),dim = 1)\n",
        "        \n",
        "        x = self.fc_model(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=-1)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtf-a1ynb8nU"
      },
      "source": [
        "net = Net().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss() #this takes into consideration that we have to differentiate through softmax layer, given softmax is not applied in our vgg\n",
        "opt = optim.SGD(net.parameters(), lr=0.1)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=len(trainloader)*5, gamma=0.1)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b0z0OoOEaFL",
        "outputId": "71b30e33-ed62-4d0d-fde7-ea03540a29c5"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#vgg = models.vgg16()\n",
        "summary(net, (3, 32, 32))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,296\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              ReLU-3           [-1, 48, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 30, 30]          20,736\n",
            "       BatchNorm2d-5           [-1, 48, 30, 30]              96\n",
            "              ReLU-6           [-1, 48, 30, 30]               0\n",
            "         MaxPool2d-7           [-1, 48, 15, 15]               0\n",
            "           Dropout-8           [-1, 48, 15, 15]               0\n",
            "            Conv2d-9           [-1, 96, 15, 15]          41,472\n",
            "      BatchNorm2d-10           [-1, 96, 15, 15]             192\n",
            "             ReLU-11           [-1, 96, 15, 15]               0\n",
            "           Conv2d-12           [-1, 96, 13, 13]          82,944\n",
            "      BatchNorm2d-13           [-1, 96, 13, 13]             192\n",
            "             ReLU-14           [-1, 96, 13, 13]               0\n",
            "        MaxPool2d-15             [-1, 96, 6, 6]               0\n",
            "          Dropout-16             [-1, 96, 6, 6]               0\n",
            "           Conv2d-17            [-1, 192, 6, 6]         165,888\n",
            "      BatchNorm2d-18            [-1, 192, 6, 6]             384\n",
            "             ReLU-19            [-1, 192, 6, 6]               0\n",
            "           Conv2d-20            [-1, 192, 4, 4]         331,776\n",
            "      BatchNorm2d-21            [-1, 192, 4, 4]             384\n",
            "             ReLU-22            [-1, 192, 4, 4]               0\n",
            "          Dropout-23            [-1, 192, 4, 4]               0\n",
            "           Linear-24                  [-1, 512]       3,146,240\n",
            "             ReLU-25                  [-1, 512]               0\n",
            "          Dropout-26                  [-1, 512]               0\n",
            "           Linear-27                  [-1, 512]         262,656\n",
            "             ReLU-28                  [-1, 512]               0\n",
            "          Dropout-29                  [-1, 512]               0\n",
            "           Linear-30                  [-1, 256]         131,328\n",
            "           Linear-31                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 4,188,250\n",
            "Trainable params: 4,188,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.47\n",
            "Params size (MB): 15.98\n",
            "Estimated Total Size (MB): 19.46\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IQQnQfzb0Fa"
      },
      "source": [
        "def evaluation(dataloader,model): \n",
        "  total , correct = 0,0\n",
        "  for data in dataloader:\n",
        "    inputs,labels = data\n",
        "    inputs,labels = inputs.to(device),labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _,pred = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels.squeeze()).sum().item()\n",
        "  return 100 * correct / total"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmqCVE6unG_T",
        "outputId": "2c6a7aa5-3552-4436-b536-8621c7d72e6c"
      },
      "source": [
        "loss_epoch_arr = []\n",
        "max_epochs = 25\n",
        "batch_size = 32\n",
        "min_loss = 1000\n",
        "\n",
        "n_iters = np.ceil(50000/batch_size)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels.squeeze())\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        #scheduler.step()\n",
        "        \n",
        "        if min_loss > loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(net.state_dict())\n",
        "            print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
        "            \n",
        "        del inputs, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "    loss_epoch_arr.append(loss.item())\n",
        "        \n",
        "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
        "        epoch, max_epochs, \n",
        "        evaluation(valloader, net), \n",
        "        evaluation(trainloader, net)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min loss 2.32\n",
            "Iteration: 0/1563, Loss: 2.32\n",
            "Min loss 2.29\n",
            "Min loss 2.25\n",
            "Min loss 2.19\n",
            "Min loss 2.13\n",
            "Min loss 2.08\n",
            "Min loss 2.02\n",
            "Min loss 1.88\n",
            "Min loss 1.79\n",
            "Min loss 1.62\n",
            "Min loss 1.53\n",
            "Min loss 1.22\n",
            "Min loss 1.18\n",
            "Min loss 0.72\n",
            "Epoch: 0/25, Test acc: 77.53, Train acc: 82.50\n",
            "Min loss 0.66\n",
            "Iteration: 0/1563, Loss: 0.66\n",
            "Min loss 0.64\n",
            "Min loss 0.64\n",
            "Min loss 0.40\n",
            "Min loss 0.31\n",
            "Min loss 0.26\n",
            "Min loss 0.23\n",
            "Epoch: 1/25, Test acc: 86.52, Train acc: 93.30\n",
            "Iteration: 0/1563, Loss: 0.30\n",
            "Min loss 0.20\n",
            "Min loss 0.17\n",
            "Min loss 0.07\n",
            "Epoch: 2/25, Test acc: 91.57, Train acc: 96.30\n",
            "Iteration: 0/1563, Loss: 0.22\n",
            "Min loss 0.06\n",
            "Min loss 0.05\n",
            "Epoch: 3/25, Test acc: 92.70, Train acc: 97.20\n",
            "Iteration: 0/1563, Loss: 0.12\n",
            "Min loss 0.04\n",
            "Min loss 0.02\n",
            "Min loss 0.01\n",
            "Epoch: 4/25, Test acc: 96.07, Train acc: 99.00\n",
            "Iteration: 0/1563, Loss: 0.04\n",
            "Min loss 0.01\n",
            "Epoch: 5/25, Test acc: 96.07, Train acc: 99.20\n",
            "Iteration: 0/1563, Loss: 0.02\n",
            "Min loss 0.01\n",
            "Epoch: 6/25, Test acc: 94.38, Train acc: 99.10\n",
            "Min loss 0.01\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Min loss 0.01\n",
            "Min loss 0.01\n",
            "Epoch: 7/25, Test acc: 95.51, Train acc: 99.30\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Min loss 0.00\n",
            "Epoch: 8/25, Test acc: 97.75, Train acc: 99.80\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Epoch: 9/25, Test acc: 93.26, Train acc: 99.70\n",
            "Iteration: 0/1563, Loss: 0.02\n",
            "Min loss 0.00\n",
            "Epoch: 10/25, Test acc: 94.94, Train acc: 99.80\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Min loss 0.00\n",
            "Min loss 0.00\n",
            "Epoch: 11/25, Test acc: 96.07, Train acc: 99.90\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 12/25, Test acc: 97.19, Train acc: 99.80\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Epoch: 13/25, Test acc: 97.19, Train acc: 99.90\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Min loss 0.00\n",
            "Epoch: 14/25, Test acc: 96.63, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 15/25, Test acc: 97.75, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 16/25, Test acc: 96.07, Train acc: 99.70\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Min loss 0.00\n",
            "Epoch: 17/25, Test acc: 96.07, Train acc: 99.90\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Epoch: 18/25, Test acc: 97.19, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 19/25, Test acc: 94.38, Train acc: 99.90\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Min loss 0.00\n",
            "Min loss 0.00\n",
            "Epoch: 20/25, Test acc: 97.19, Train acc: 99.90\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 21/25, Test acc: 97.19, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.01\n",
            "Epoch: 22/25, Test acc: 97.19, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Min loss 0.00\n",
            "Epoch: 23/25, Test acc: 97.19, Train acc: 100.00\n",
            "Iteration: 0/1563, Loss: 0.00\n",
            "Epoch: 24/25, Test acc: 95.51, Train acc: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNbjbEVYofhW",
        "outputId": "1f360d7d-b6b8-416f-8bea-f9e0a3beb10b"
      },
      "source": [
        "net.load_state_dict(best_model)\n",
        "print(evaluation(trainloader, net), evaluation(valloader, net))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.0 97.75280898876404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lNFnexOaHcvI",
        "outputId": "a948effe-c3bb-42cd-9dcf-5fe821c0400b"
      },
      "source": [
        "plt.plot(loss_epoch_arr)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxGl5lIEImlv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}