{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR9btWSgzC4ouEGpZ0qKK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/ML_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg5xXYK-iO6U"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOhU-67EqnJy"
      },
      "source": [
        "# Question 1 \n",
        "\n",
        "## Dataset : Iris Dataset\n",
        "\n",
        "Use sklearn library for loading iris dataset.\n",
        "\n",
        "__Aim__: Classification using Naive Bayes classifier\n",
        "\n",
        "```\n",
        "‚óè Apply Naive bayes classifier assuming all features are independent.\n",
        "Do not use any predefined library for classification\n",
        "Report overall accuracy, class wise accuracy, confusion matrix and ROC curve.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szCnGYKNqe-5"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORqKTDbsaP2"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_N1d3ykq8q7"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "df_iris = pd.DataFrame(iris.data,columns = iris.feature_names)\n",
        "df_iris['target'] = iris.target"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y34CoChTwfBG",
        "outputId": "4c0869ea-1048-4418-95b7-74aa08e9510f"
      },
      "source": [
        "X, y = df_iris.iloc[:, :-1], df_iris.iloc[:, -1]\n",
        "\n",
        "# # split on train and test 0.7/0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1, stratify=y)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75, 4) (75,)\n",
            "(75, 4) (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvWkNfaXZGRp",
        "outputId": "6071fc95-1df7-4bce-ca8f-cc27fad6400e"
      },
      "source": [
        "df_iris.target.unique()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaLpdDQs8qL"
      },
      "source": [
        "### Creating a Naive Bayes class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQfy9cqHsK80"
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "\n",
        "  \"\"\"\n",
        "  Bayes Theorem : \n",
        "\n",
        "  P(y|X) = (P(X|y)*P(y))/P(X)\n",
        "\n",
        "  where :\n",
        "  X : Input Features\n",
        "  y : Traget Variable\n",
        "  P(y|X) = Posterior Probability\n",
        "  P(X|y) = Liklihood\n",
        "  P(y) = Prior\n",
        "  P(X) = Evidence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,prior = None):\n",
        "\n",
        "    self.liklihood = {}\n",
        "    self.posteriors = []\n",
        "    self.prediction = []\n",
        "    self.mean = None\n",
        "    self.variance = None \n",
        "    if prior :\n",
        "      self.prior = prior\n",
        "    else :\n",
        "      self.prior = {} \n",
        " \n",
        "  def calculate_prior(self ,target ,classes):\n",
        "    \"\"\"\n",
        "    This function calculates the prior probabilities\n",
        "    \"\"\"\n",
        "    prior = {}\n",
        "    for index in classes:\n",
        "      prior[index] = (target == index).sum()/len(target) \n",
        "    return prior\n",
        "\n",
        "\n",
        "  def feature_statistics(self , features , target):\n",
        "    \"\"\"\n",
        "    This function calculates mean and variance for continuous features\n",
        "    \"\"\"\n",
        "    var = lambda x : np.var(x)  \n",
        "    mean = features.groupby(target).mean().reset_index()\n",
        "    #mean = features.groupby(y_train).agg({'sepal length (cm)' : 'mean',\t'sepal width (cm)': 'mean',\t'petal length (cm)': 'mean',\t'petal width (cm)': 'mean'}).reset_index()\n",
        "    #variance = features.groupby(y_train).agg({'sepal length (cm)' : var,\t'sepal width (cm)': var,\t'petal length (cm)': var,\t'petal width (cm)': var}).reset_index()\n",
        "    variance = features.groupby(target).var(ddof = 0).reset_index()\n",
        "    return mean , variance\n",
        "\n",
        "\n",
        "  def gaussian_probability(self,test_feature,classes, mean, variance):\n",
        "    liklihood_prob = {}\n",
        "    for index in classes:\n",
        "      mean_vector = np.array(mean[mean['target'] == index])[0][1:]\n",
        "      variance_vector = np.array(variance[variance['target'] == index])[0][1:]\n",
        "      mean_diff_square = (np.array(test_feature) - mean_vector)**2\n",
        "      liklihood_prob[index] = (1/np.sqrt(2*np.pi*variance_vector)*np.exp(-1*0.5*mean_diff_square/variance_vector))\n",
        "    return liklihood_prob\n",
        "\n",
        "\n",
        "  def calculate_posterior(self,test_feature,classes):\n",
        "\n",
        "    posteriors = {}\n",
        "    self.liklihood = self.gaussian_probability(test_feature ,classes ,self.mean,self.variance)\n",
        "    for index in classes :\n",
        "      posteriors[index] = reduce(lambda x , y : x*y , self.liklihood[index]) * self.prior[index]\n",
        "    return posteriors\n",
        "\n",
        "\n",
        "  def fit(self, features, target):\n",
        "    self.classes = target.unique()\n",
        "    if self.prior :\n",
        "      pass\n",
        "    else:\n",
        "      self.prior = self.calculate_prior(target , self.classes)\n",
        "    self.mean , self.variance = self.feature_statistics(features , target)\n",
        "    \n",
        "\n",
        "  def predict(self,test_features):\n",
        "    for i in range(len(test_features)):\n",
        "      self.posteriors.append(self.calculate_posterior(test_features.iloc[i].values,self.classes))\n",
        "      self.prediction.append(sorted(self.posteriors[i].items(),key = lambda x : x[1],reverse = True)[0][0])\n",
        "    #return(self.prediction)\n",
        "\n",
        "  def accuracy(self , target,names):\n",
        "\n",
        "    overall_accuracy = sum(target == self.prediction) / len(target)\n",
        "    print(f\"Overall accuracy of data : {round(overall_accuracy*100,2)}%\")\n",
        "\n",
        "    data = pd.DataFrame({'Actual Class' : target.values,'Predicted Class':self.prediction})\n",
        "    for class_ in target.unique():\n",
        "      temp = data[data['Actual Class'] == class_]\n",
        "      print(f\"{names[class_]} accuracy of data : {round(sum(temp['Actual Class'] == temp['Predicted Class']) / len(temp)*100,2)}%\")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmbagMWN_ktb"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfFYQZFt-r3G"
      },
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy83k_qAMX7j",
        "outputId": "c3718ed8-d6d9-4d54-94e0-7de304131063"
      },
      "source": [
        "model.prior"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Asyz-T3_qLi"
      },
      "source": [
        "### Making predictions using trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ncSlWssTVX"
      },
      "source": [
        "model.predict(X_test) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inFT82lovrSh",
        "outputId": "af2cd847-bc83-4ad7-c0fe-eff8f8599216"
      },
      "source": [
        "model.accuracy(y_test,iris.target_names)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 97.33%\n",
            "virginica accuracy of data : 96.0%\n",
            "setosa accuracy of data : 100.0%\n",
            "versicolor accuracy of data : 96.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z3ANM7b9Zsm"
      },
      "source": [
        "# Question 2 :\n",
        "\n",
        "__Dataset__: Wine dataset (use sklearn library for loading the dataset)\n",
        "\n",
        "__Aim__: Naive Bayes Classification\n",
        "```\n",
        "Shuffle the data with seed value 42 and perform a 70- 30 stratified split of the data into a train and test set.\n",
        "Also, plot the class-wise distribution of data in the train and test set (one for train set and one for test set).\n",
        "\n",
        "Compare the distributions. Now, perform classification as follows:\n",
        "\n",
        "* Train a Gaussian Naive Bayes classifier and report (a) the class priors, (b) mean and variance of\n",
        "each feature per class.\n",
        "\n",
        "* Train another Gaussian Naive Bayes classifier by setting prior probability for the classes. Repeat this\n",
        "experiment by setting priors in the ratios: (a) 40-40-20 and (b) 80-10-10.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKTASQVvv47L"
      },
      "source": [
        "wine = datasets.load_wine()\n",
        "df_wine = pd.DataFrame(wine.data,columns = wine.feature_names)\n",
        "df_wine['target'] = wine.target"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QEuzObr-qsW",
        "outputId": "d0e6698e-4be6-4e7f-92db-36ee753364f3"
      },
      "source": [
        "X, y = df_wine.iloc[:, :-1], df_wine.iloc[:, -1]\n",
        "\n",
        "# # split on train and test 0.7/0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124, 13) (124,)\n",
            "(54, 13) (54,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t79-MBV-86s",
        "outputId": "29a094e8-fb93-4b8d-e82d-eb5470682f5b"
      },
      "source": [
        "df_wine.target.unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn6FYZoZrnkW"
      },
      "source": [
        "### Plotting Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfYN9ToTr0Lv",
        "outputId": "f7a0fb34-be7d-482f-bda3-c36cc5dfde43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "df_wine"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows √ó 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  target\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0       0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0       0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0       0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0       0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0       0\n",
              "..       ...         ...   ...  ...                           ...      ...     ...\n",
              "173    13.71        5.65  2.45  ...                          1.74    740.0       2\n",
              "174    13.40        3.91  2.48  ...                          1.56    750.0       2\n",
              "175    13.27        4.28  2.26  ...                          1.56    835.0       2\n",
              "176    13.17        2.59  2.37  ...                          1.62    840.0       2\n",
              "177    14.13        4.10  2.74  ...                          1.60    560.0       2\n",
              "\n",
              "[178 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvyev7y1_81U"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyExHW6l_81i"
      },
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jq7rTCJ_81l"
      },
      "source": [
        "### Making predictions using trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeIQXhzP_81l"
      },
      "source": [
        "model.predict(X_test) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40OUU6VP_81m",
        "outputId": "1c10146c-f6a9-4721-d4bb-47b33616e7f5"
      },
      "source": [
        "model.accuracy(y_test,wine.target_names)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 100.0%\n",
            "class_0 accuracy of data : 100.0%\n",
            "class_1 accuracy of data : 100.0%\n",
            "class_2 accuracy of data : 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vLg-hxYWln0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d789ba19-6d03-45d6-8497-00aabe4ef064"
      },
      "source": [
        "model.prior"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.33064516129032256, 1: 0.4032258064516129, 2: 0.2661290322580645}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaJQapkMcdjT"
      },
      "source": [
        "#### Adjusting prior to 40-40-20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf_qTdI8buzn",
        "outputId": "1c53e06a-1bfa-477a-86e9-d26c33a1a810"
      },
      "source": [
        "prior = {0: 0.40, 1: 0.40, 2: 0.20}\n",
        "model = NaiveBayesClassifier(prior)\n",
        "model.fit(X_train, y_train)\n",
        "model.predict(X_test) \n",
        "model.accuracy(y_test,wine.target_names)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 98.15%\n",
            "class_0 accuracy of data : 100.0%\n",
            "class_1 accuracy of data : 95.24%\n",
            "class_2 accuracy of data : 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIhYrPAXcxMW",
        "outputId": "13136bb2-3b43-448d-d7d7-a17aaa45aa16"
      },
      "source": [
        "prior = {0: 0.80, 1: 0.10, 2: 0.10}\n",
        "model = NaiveBayesClassifier(prior)\n",
        "model.fit(X_train, y_train)\n",
        "model.predict(X_test) \n",
        "model.accuracy(y_test,wine.target_names)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 98.15%\n",
            "class_0 accuracy of data : 100.0%\n",
            "class_1 accuracy of data : 95.24%\n",
            "class_2 accuracy of data : 100.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}