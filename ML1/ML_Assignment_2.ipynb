{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPapq8j2Hmj23+3xyIjg62z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/MTech_Atificial_Intelligence/blob/main/ML1/ML_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOhU-67EqnJy"
      },
      "source": [
        "# Question 1 \n",
        "\n",
        "## Dataset : Iris Dataset\n",
        "\n",
        "Use sklearn library for loading iris dataset.\n",
        "\n",
        "__Aim__: Classification using Naive Bayes classifier\n",
        "\n",
        "```\n",
        "‚óè Apply Naive bayes classifier assuming all features are independent.\n",
        "Do not use any predefined library for classification\n",
        "Report overall accuracy, class wise accuracy, confusion matrix and ROC curve.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szCnGYKNqe-5"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from functools import reduce"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORqKTDbsaP2"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_N1d3ykq8q7"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "df_iris = pd.DataFrame(iris.data,columns = iris.feature_names)\n",
        "df_iris['target'] = iris.target"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y34CoChTwfBG",
        "outputId": "70c20179-db1c-4cb9-9a27-34e0790f94a6"
      },
      "source": [
        "X, y = df_iris.iloc[:, :-1], df_iris.iloc[:, -1]\n",
        "\n",
        "# # split on train and test 0.7/0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1, stratify=y)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75, 4) (75,)\n",
            "(75, 4) (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvWkNfaXZGRp",
        "outputId": "839f9ebe-0097-4294-a5d8-a84dac53220e"
      },
      "source": [
        "df_iris.target.unique()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaLpdDQs8qL"
      },
      "source": [
        "### Creating a Naive Bayes class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQfy9cqHsK80"
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "\n",
        "  \"\"\"\n",
        "  Bayes Theorem : \n",
        "\n",
        "  P(y|X) = (P(X|y)*P(y))/P(X)\n",
        "\n",
        "  where :\n",
        "  X : Input Features\n",
        "  y : Traget Variable\n",
        "  P(y|X) = Posterior Probability\n",
        "  P(X|y) = Liklihood\n",
        "  P(y) = Prior\n",
        "  P(X) = Evidence\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,prior = None):\n",
        "\n",
        "    self.liklihood = {}\n",
        "    self.posteriors = []\n",
        "    self.prediction = []\n",
        "    self.mean = None\n",
        "    self.variance = None \n",
        "    if prior :\n",
        "      self.prior = prior\n",
        "    else :\n",
        "      self.prior = {} \n",
        " \n",
        "  def calculate_prior(self ,target ,classes):\n",
        "    \"\"\"\n",
        "    This function calculates the prior probabilities\n",
        "    \"\"\"\n",
        "    prior = {}\n",
        "    for index in classes:\n",
        "      prior[index] = (target == index).sum()/len(target) \n",
        "    return prior\n",
        "\n",
        "\n",
        "  def feature_statistics(self , features , target):\n",
        "    \"\"\"\n",
        "    This function calculates mean and variance for continuous features\n",
        "    \"\"\"\n",
        "    var = lambda x : np.var(x)  \n",
        "    mean = features.groupby(y_train).agg({'sepal length (cm)' : 'mean',\t'sepal width (cm)': 'mean',\t'petal length (cm)': 'mean',\t'petal width (cm)': 'mean'}).reset_index()\n",
        "    variance = features.groupby(y_train).agg({'sepal length (cm)' : var,\t'sepal width (cm)': var,\t'petal length (cm)': var,\t'petal width (cm)': var}).reset_index()\n",
        "    \n",
        "    return mean , variance\n",
        "\n",
        "\n",
        "  def gaussian_probability(self,test_feature,classes, mean, variance):\n",
        "    liklihood_prob = {}\n",
        "    for index in classes:\n",
        "      mean_vector = np.array(mean[mean['target'] == index])[0][1:]\n",
        "      variance_vector = np.array(variance[variance['target'] == index])[0][1:]\n",
        "      mean_diff_square = (np.array(test_feature) - mean_vector)**2\n",
        "      liklihood_prob[index] = (1/np.sqrt(2*np.pi*variance_vector)*np.exp(-1*0.5*mean_diff_square/variance_vector))\n",
        "    return liklihood_prob\n",
        "\n",
        "\n",
        "  def calculate_posterior(self,test_feature,classes):\n",
        "\n",
        "    posteriors = {}\n",
        "    self.liklihood = self.gaussian_probability(test_feature ,classes ,self.mean,self.variance)\n",
        "    for index in classes :\n",
        "      posteriors[index] = reduce(lambda x , y : x*y , self.liklihood[index]) * self.prior[index]\n",
        "    return posteriors\n",
        "\n",
        "\n",
        "  def fit(self, features, target):\n",
        "    self.classes = target.unique()\n",
        "    self.mean , self.variance = self.feature_statistics(features , target)\n",
        "    \n",
        "    if self.prior :\n",
        "      self.prior = self.calculate_prior(target , self.classes)\n",
        "\n",
        "  def predict(self,test_features):\n",
        "    for i in range(len(test_features)):\n",
        "      self.posteriors.append(self.calculate_posterior(test_features.iloc[i].values,self.classes))\n",
        "      self.prediction.append(sorted(self.posteriors[i].items(),key = lambda x : x[1],reverse = True)[0][0])\n",
        "    #return(self.prediction)\n",
        "\n",
        "  def accuracy(self , target,names):\n",
        "\n",
        "    overall_accuracy = sum(target == self.prediction) / len(target)\n",
        "    print(f\"Overall accuracy of data : {round(overall_accuracy*100,2)}%\")\n",
        "\n",
        "    data = pd.DataFrame({'Actual Class' : target.values,'Predicted Class':self.prediction})\n",
        "    for class_ in target.unique():\n",
        "      temp = data[data['Actual Class'] == class_]\n",
        "      print(f\"{names[class_]} accuracy of data : {round(sum(temp['Actual Class'] == temp['Predicted Class']) / len(temp)*100,2)}%\")\n",
        "\n"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmbagMWN_ktb"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfFYQZFt-r3G"
      },
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Asyz-T3_qLi"
      },
      "source": [
        "### Making predictions using trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ncSlWssTVX"
      },
      "source": [
        "model.predict(X_test) "
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inFT82lovrSh",
        "outputId": "725a7138-00e8-4463-e846-e34f90d4ed71"
      },
      "source": [
        "model.accuracy(y_test,iris.target_names)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 97.33%\n",
            "virginica accuracy of data : 96.0%\n",
            "setosa accuracy of data : 100.0%\n",
            "versicolor accuracy of data : 96.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z3ANM7b9Zsm"
      },
      "source": [
        "# Question 2 :\n",
        "\n",
        "__Dataset__: Wine dataset (use sklearn library for loading the dataset)\n",
        "\n",
        "__Aim__: Naive Bayes Classification\n",
        "```\n",
        "Shuffle the data with seed value 42 and perform a 70- 30 stratified split of the data into a train and test set.\n",
        "Also, plot the class-wise distribution of data in the train and test set (one for train set and one for test set).\n",
        "\n",
        "Compare the distributions. Now, perform classification as follows:\n",
        "\n",
        "* Train a Gaussian Naive Bayes classifier and report (a) the class priors, (b) mean and variance of\n",
        "each feature per class.\n",
        "\n",
        "* Train another Gaussian Naive Bayes classifier by setting prior probability for the classes. Repeat this\n",
        "experiment by setting priors in the ratios: (a) 40-40-20 and (b) 80-10-10.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKTASQVvv47L"
      },
      "source": [
        "wine = datasets.load_wine()\n",
        "df_wine = pd.DataFrame(wine.data,columns = wine.feature_names)\n",
        "df_wine['target'] = wine.target"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QEuzObr-qsW",
        "outputId": "a7f1b992-5e82-4f51-9d09-f142b603a721"
      },
      "source": [
        "X, y = df_wine.iloc[:, :-1], df_wine.iloc[:, -1]\n",
        "\n",
        "# # split on train and test 0.7/0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1, stratify=y)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(89, 13) (89,)\n",
            "(89, 13) (89,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t79-MBV-86s",
        "outputId": "6dcae0b6-9452-49ca-c00c-1c3f4eece8c7"
      },
      "source": [
        "df_wine.target.unique()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvyev7y1_81U"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "xyExHW6l_81i",
        "outputId": "61e9e1a8-a3bb-456b-c532-e23e1146b3ea"
      },
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SpecificationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSpecificationError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-945f964b53ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-189-8bf42ef781c5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-189-8bf42ef781c5>\u001b[0m in \u001b[0;36mfeature_statistics\u001b[0;34m(self, features, target)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sepal length (cm)'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sepal width (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;34m'petal length (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;34m'petal width (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'sepal length (cm)'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m'sepal width (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m'petal length (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;34m'petal width (cm)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 ) != len(keys):\n\u001b[1;32m    353\u001b[0m                     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column(s) {cols} do not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSpecificationError\u001b[0m: Column(s) ['petal length (cm)', 'petal width (cm)', 'sepal length (cm)', 'sepal width (cm)'] do not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jq7rTCJ_81l"
      },
      "source": [
        "### Making predictions using trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeIQXhzP_81l"
      },
      "source": [
        "model.predict(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40OUU6VP_81m",
        "outputId": "725a7138-00e8-4463-e846-e34f90d4ed71"
      },
      "source": [
        "model.accuracy(y_test,iris.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy of data : 97.33%\n",
            "virginica accuracy of data : 96.0%\n",
            "setosa accuracy of data : 100.0%\n",
            "versicolor accuracy of data : 96.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}